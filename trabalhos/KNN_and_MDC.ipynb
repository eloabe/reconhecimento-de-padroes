{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "galatasEloabe_rp_trab01.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Xt134bw32WG-",
        "bV337glT2ZOe",
        "EF2Nj27l2L77",
        "CYMkqLqD2kaf",
        "AtCDdSnNnd8_",
        "V8VJd0ZgGMuZ",
        "KXdTmGnUCA50",
        "qfw3DHHgDBfv"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyo87Dpx2Tru"
      },
      "source": [
        "#Trabalho 1 de RP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt134bw32WG-"
      },
      "source": [
        "## Importação de bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0p_xzCscvuP"
      },
      "source": [
        "import random\n",
        "\n",
        "import numpy              as np\n",
        "import pandas             as pd\n",
        "import seaborn            as sns\n",
        "import scipy.stats        as ss\n",
        "import matplotlib.pyplot  as plt\n",
        "\n",
        "from collections                import Counter\n",
        "from sklearn.preprocessing      import MinMaxScaler\n",
        "from sklearn.model_selection    import train_test_split"
      ],
      "execution_count": 522,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV337glT2ZOe"
      },
      "source": [
        "## Carregamento dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df9TdCnDdYaF"
      },
      "source": [
        "audio_path = '/content/drive/MyDrive/UFC/Reconhecimento de Padrões/trab1/audio.txt'\n",
        "ecg_path = '/content/drive/MyDrive/UFC/Reconhecimento de Padrões/trab1/ecg.txt'\n",
        "\n",
        "audio = pd.read_fwf(audio_path, header=None).T\n",
        "ecg = pd.read_fwf(ecg_path, header=None).T"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "pPUR8v9giA2R",
        "outputId": "3c26af95-c44b-4ba7-91d5-a47f39aca589"
      },
      "source": [
        "#criando uma nova coluna em cada dataset para definir qual é a classe\n",
        "#vamos codificar as classes como ecg = 1 e audio = 2\n",
        "ecg[500] = 1\n",
        "audio[500] = 2\n",
        "\n",
        "#juntando os dois conjuntos de dados\n",
        "dados = pd.concat([audio, ecg]).reset_index(drop=True)\n",
        "dados[500] = dados[500].astype('float64')\n",
        "dados.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>461</th>\n",
              "      <th>462</th>\n",
              "      <th>463</th>\n",
              "      <th>464</th>\n",
              "      <th>465</th>\n",
              "      <th>466</th>\n",
              "      <th>467</th>\n",
              "      <th>468</th>\n",
              "      <th>469</th>\n",
              "      <th>470</th>\n",
              "      <th>471</th>\n",
              "      <th>472</th>\n",
              "      <th>473</th>\n",
              "      <th>474</th>\n",
              "      <th>475</th>\n",
              "      <th>476</th>\n",
              "      <th>477</th>\n",
              "      <th>478</th>\n",
              "      <th>479</th>\n",
              "      <th>480</th>\n",
              "      <th>481</th>\n",
              "      <th>482</th>\n",
              "      <th>483</th>\n",
              "      <th>484</th>\n",
              "      <th>485</th>\n",
              "      <th>486</th>\n",
              "      <th>487</th>\n",
              "      <th>488</th>\n",
              "      <th>489</th>\n",
              "      <th>490</th>\n",
              "      <th>491</th>\n",
              "      <th>492</th>\n",
              "      <th>493</th>\n",
              "      <th>494</th>\n",
              "      <th>495</th>\n",
              "      <th>496</th>\n",
              "      <th>497</th>\n",
              "      <th>498</th>\n",
              "      <th>499</th>\n",
              "      <th>500</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.005149</td>\n",
              "      <td>-0.001660</td>\n",
              "      <td>-0.003860</td>\n",
              "      <td>-0.003754</td>\n",
              "      <td>0.002709</td>\n",
              "      <td>-0.000123</td>\n",
              "      <td>-0.002560</td>\n",
              "      <td>0.001240</td>\n",
              "      <td>-0.003455</td>\n",
              "      <td>-0.005611</td>\n",
              "      <td>0.003590</td>\n",
              "      <td>-0.001982</td>\n",
              "      <td>-0.000094</td>\n",
              "      <td>0.001678</td>\n",
              "      <td>0.001734</td>\n",
              "      <td>-0.004379</td>\n",
              "      <td>0.002003</td>\n",
              "      <td>0.000996</td>\n",
              "      <td>-0.001048</td>\n",
              "      <td>-0.000696</td>\n",
              "      <td>-0.001956</td>\n",
              "      <td>-0.003136</td>\n",
              "      <td>-0.007412</td>\n",
              "      <td>0.002380</td>\n",
              "      <td>-0.000892</td>\n",
              "      <td>-0.003432</td>\n",
              "      <td>0.002215</td>\n",
              "      <td>0.004747</td>\n",
              "      <td>-0.003286</td>\n",
              "      <td>0.001399</td>\n",
              "      <td>0.006706</td>\n",
              "      <td>0.000978</td>\n",
              "      <td>0.001649</td>\n",
              "      <td>0.002368</td>\n",
              "      <td>0.006938</td>\n",
              "      <td>0.002751</td>\n",
              "      <td>0.004173</td>\n",
              "      <td>0.011070</td>\n",
              "      <td>0.008020</td>\n",
              "      <td>0.008687</td>\n",
              "      <td>...</td>\n",
              "      <td>0.016297</td>\n",
              "      <td>0.023054</td>\n",
              "      <td>0.022364</td>\n",
              "      <td>0.020354</td>\n",
              "      <td>0.022156</td>\n",
              "      <td>0.021733</td>\n",
              "      <td>0.015891</td>\n",
              "      <td>0.017690</td>\n",
              "      <td>0.020103</td>\n",
              "      <td>0.019006</td>\n",
              "      <td>0.023227</td>\n",
              "      <td>0.018877</td>\n",
              "      <td>0.020710</td>\n",
              "      <td>0.016387</td>\n",
              "      <td>0.021444</td>\n",
              "      <td>0.017803</td>\n",
              "      <td>0.020130</td>\n",
              "      <td>0.019386</td>\n",
              "      <td>0.020986</td>\n",
              "      <td>0.016347</td>\n",
              "      <td>0.023917</td>\n",
              "      <td>0.023956</td>\n",
              "      <td>0.023434</td>\n",
              "      <td>0.021784</td>\n",
              "      <td>0.019859</td>\n",
              "      <td>0.022752</td>\n",
              "      <td>0.017351</td>\n",
              "      <td>0.022025</td>\n",
              "      <td>0.019842</td>\n",
              "      <td>0.022705</td>\n",
              "      <td>0.016021</td>\n",
              "      <td>0.011144</td>\n",
              "      <td>0.001415</td>\n",
              "      <td>-0.002953</td>\n",
              "      <td>-0.012756</td>\n",
              "      <td>-0.016865</td>\n",
              "      <td>-0.015602</td>\n",
              "      <td>-0.018967</td>\n",
              "      <td>-0.014244</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.117753</td>\n",
              "      <td>-0.191172</td>\n",
              "      <td>-0.095776</td>\n",
              "      <td>-0.069015</td>\n",
              "      <td>-0.298852</td>\n",
              "      <td>-0.224581</td>\n",
              "      <td>-0.088905</td>\n",
              "      <td>-0.148663</td>\n",
              "      <td>0.127519</td>\n",
              "      <td>-0.154734</td>\n",
              "      <td>0.173246</td>\n",
              "      <td>0.071701</td>\n",
              "      <td>0.208361</td>\n",
              "      <td>0.128268</td>\n",
              "      <td>-0.101804</td>\n",
              "      <td>0.166985</td>\n",
              "      <td>0.100920</td>\n",
              "      <td>-0.006563</td>\n",
              "      <td>-0.197145</td>\n",
              "      <td>-0.290473</td>\n",
              "      <td>-0.171338</td>\n",
              "      <td>-0.103005</td>\n",
              "      <td>-0.089740</td>\n",
              "      <td>-0.094189</td>\n",
              "      <td>0.020907</td>\n",
              "      <td>-0.047127</td>\n",
              "      <td>0.026159</td>\n",
              "      <td>-0.090350</td>\n",
              "      <td>0.170042</td>\n",
              "      <td>-0.050371</td>\n",
              "      <td>0.223437</td>\n",
              "      <td>0.283175</td>\n",
              "      <td>0.207617</td>\n",
              "      <td>0.241713</td>\n",
              "      <td>0.264826</td>\n",
              "      <td>0.213508</td>\n",
              "      <td>0.339327</td>\n",
              "      <td>0.162842</td>\n",
              "      <td>0.443644</td>\n",
              "      <td>0.211835</td>\n",
              "      <td>...</td>\n",
              "      <td>0.867094</td>\n",
              "      <td>0.948768</td>\n",
              "      <td>0.676437</td>\n",
              "      <td>0.920074</td>\n",
              "      <td>0.860320</td>\n",
              "      <td>0.882959</td>\n",
              "      <td>0.611354</td>\n",
              "      <td>0.674262</td>\n",
              "      <td>0.918792</td>\n",
              "      <td>0.785111</td>\n",
              "      <td>0.719300</td>\n",
              "      <td>0.812615</td>\n",
              "      <td>0.612957</td>\n",
              "      <td>0.798233</td>\n",
              "      <td>0.970026</td>\n",
              "      <td>0.594748</td>\n",
              "      <td>0.908009</td>\n",
              "      <td>0.903170</td>\n",
              "      <td>0.713200</td>\n",
              "      <td>0.948076</td>\n",
              "      <td>0.791931</td>\n",
              "      <td>1.045358</td>\n",
              "      <td>0.980178</td>\n",
              "      <td>0.801386</td>\n",
              "      <td>0.910564</td>\n",
              "      <td>0.857387</td>\n",
              "      <td>0.858396</td>\n",
              "      <td>0.707975</td>\n",
              "      <td>0.776226</td>\n",
              "      <td>0.815241</td>\n",
              "      <td>0.766644</td>\n",
              "      <td>0.203609</td>\n",
              "      <td>0.174668</td>\n",
              "      <td>-0.140126</td>\n",
              "      <td>-0.238385</td>\n",
              "      <td>-0.671537</td>\n",
              "      <td>-0.816351</td>\n",
              "      <td>-0.821680</td>\n",
              "      <td>-0.735269</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.531884</td>\n",
              "      <td>-0.102584</td>\n",
              "      <td>-0.307340</td>\n",
              "      <td>0.154307</td>\n",
              "      <td>-0.455531</td>\n",
              "      <td>-0.031878</td>\n",
              "      <td>-0.081085</td>\n",
              "      <td>-0.378268</td>\n",
              "      <td>-0.187602</td>\n",
              "      <td>0.072513</td>\n",
              "      <td>0.109888</td>\n",
              "      <td>-0.149852</td>\n",
              "      <td>0.334613</td>\n",
              "      <td>-0.192338</td>\n",
              "      <td>0.054723</td>\n",
              "      <td>-0.041921</td>\n",
              "      <td>-0.083285</td>\n",
              "      <td>-0.092268</td>\n",
              "      <td>-0.112072</td>\n",
              "      <td>-0.379974</td>\n",
              "      <td>-0.102834</td>\n",
              "      <td>-0.786860</td>\n",
              "      <td>-0.264004</td>\n",
              "      <td>-0.256698</td>\n",
              "      <td>-0.423231</td>\n",
              "      <td>0.134087</td>\n",
              "      <td>-0.098899</td>\n",
              "      <td>0.167452</td>\n",
              "      <td>0.744562</td>\n",
              "      <td>0.199849</td>\n",
              "      <td>0.532093</td>\n",
              "      <td>0.183467</td>\n",
              "      <td>0.255762</td>\n",
              "      <td>0.292721</td>\n",
              "      <td>0.342067</td>\n",
              "      <td>0.098273</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.621952</td>\n",
              "      <td>0.476193</td>\n",
              "      <td>0.574068</td>\n",
              "      <td>...</td>\n",
              "      <td>1.101669</td>\n",
              "      <td>1.792936</td>\n",
              "      <td>1.650656</td>\n",
              "      <td>1.304338</td>\n",
              "      <td>1.685823</td>\n",
              "      <td>1.969201</td>\n",
              "      <td>1.908508</td>\n",
              "      <td>1.859967</td>\n",
              "      <td>1.611523</td>\n",
              "      <td>1.669700</td>\n",
              "      <td>1.726059</td>\n",
              "      <td>1.634031</td>\n",
              "      <td>2.070321</td>\n",
              "      <td>1.602278</td>\n",
              "      <td>1.476003</td>\n",
              "      <td>1.108753</td>\n",
              "      <td>1.700207</td>\n",
              "      <td>1.440135</td>\n",
              "      <td>1.814036</td>\n",
              "      <td>1.408268</td>\n",
              "      <td>1.549451</td>\n",
              "      <td>1.891772</td>\n",
              "      <td>1.470527</td>\n",
              "      <td>1.656081</td>\n",
              "      <td>1.969027</td>\n",
              "      <td>1.400740</td>\n",
              "      <td>1.320829</td>\n",
              "      <td>1.248007</td>\n",
              "      <td>1.705642</td>\n",
              "      <td>1.937962</td>\n",
              "      <td>1.363380</td>\n",
              "      <td>0.716238</td>\n",
              "      <td>0.177158</td>\n",
              "      <td>-0.825243</td>\n",
              "      <td>-1.040234</td>\n",
              "      <td>-1.377452</td>\n",
              "      <td>-1.605749</td>\n",
              "      <td>-2.118144</td>\n",
              "      <td>-1.814519</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.135808</td>\n",
              "      <td>-0.096242</td>\n",
              "      <td>-0.119334</td>\n",
              "      <td>-0.021121</td>\n",
              "      <td>-0.123060</td>\n",
              "      <td>-0.139165</td>\n",
              "      <td>0.019574</td>\n",
              "      <td>-0.125935</td>\n",
              "      <td>0.027199</td>\n",
              "      <td>-0.067951</td>\n",
              "      <td>-0.046907</td>\n",
              "      <td>0.023023</td>\n",
              "      <td>0.170130</td>\n",
              "      <td>-0.067148</td>\n",
              "      <td>0.069403</td>\n",
              "      <td>-0.024285</td>\n",
              "      <td>0.009293</td>\n",
              "      <td>0.021516</td>\n",
              "      <td>0.016391</td>\n",
              "      <td>0.017949</td>\n",
              "      <td>-0.115926</td>\n",
              "      <td>-0.054423</td>\n",
              "      <td>-0.117893</td>\n",
              "      <td>-0.033041</td>\n",
              "      <td>-0.046429</td>\n",
              "      <td>-0.012722</td>\n",
              "      <td>-0.032563</td>\n",
              "      <td>0.007054</td>\n",
              "      <td>0.058330</td>\n",
              "      <td>0.133599</td>\n",
              "      <td>0.098405</td>\n",
              "      <td>0.007085</td>\n",
              "      <td>0.229250</td>\n",
              "      <td>0.060565</td>\n",
              "      <td>0.185067</td>\n",
              "      <td>0.131341</td>\n",
              "      <td>0.225133</td>\n",
              "      <td>0.090552</td>\n",
              "      <td>0.189962</td>\n",
              "      <td>0.160417</td>\n",
              "      <td>...</td>\n",
              "      <td>0.427833</td>\n",
              "      <td>0.374683</td>\n",
              "      <td>0.454835</td>\n",
              "      <td>0.580055</td>\n",
              "      <td>0.416927</td>\n",
              "      <td>0.443753</td>\n",
              "      <td>0.558807</td>\n",
              "      <td>0.456318</td>\n",
              "      <td>0.466566</td>\n",
              "      <td>0.451125</td>\n",
              "      <td>0.467961</td>\n",
              "      <td>0.409004</td>\n",
              "      <td>0.410866</td>\n",
              "      <td>0.431177</td>\n",
              "      <td>0.315473</td>\n",
              "      <td>0.495606</td>\n",
              "      <td>0.497370</td>\n",
              "      <td>0.452413</td>\n",
              "      <td>0.451614</td>\n",
              "      <td>0.551195</td>\n",
              "      <td>0.457936</td>\n",
              "      <td>0.499989</td>\n",
              "      <td>0.521137</td>\n",
              "      <td>0.396894</td>\n",
              "      <td>0.525580</td>\n",
              "      <td>0.422845</td>\n",
              "      <td>0.424764</td>\n",
              "      <td>0.448006</td>\n",
              "      <td>0.541419</td>\n",
              "      <td>0.515850</td>\n",
              "      <td>0.314915</td>\n",
              "      <td>0.133274</td>\n",
              "      <td>-0.061850</td>\n",
              "      <td>-0.071172</td>\n",
              "      <td>-0.165596</td>\n",
              "      <td>-0.366608</td>\n",
              "      <td>-0.637880</td>\n",
              "      <td>-0.528150</td>\n",
              "      <td>-0.454956</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.030297</td>\n",
              "      <td>-0.074934</td>\n",
              "      <td>-0.028709</td>\n",
              "      <td>-0.047723</td>\n",
              "      <td>-0.001417</td>\n",
              "      <td>0.003577</td>\n",
              "      <td>-0.068440</td>\n",
              "      <td>-0.058604</td>\n",
              "      <td>-0.021373</td>\n",
              "      <td>0.022441</td>\n",
              "      <td>0.062237</td>\n",
              "      <td>0.009755</td>\n",
              "      <td>0.004021</td>\n",
              "      <td>-0.030615</td>\n",
              "      <td>-0.034103</td>\n",
              "      <td>0.027449</td>\n",
              "      <td>-0.088653</td>\n",
              "      <td>-0.041343</td>\n",
              "      <td>-0.006113</td>\n",
              "      <td>-0.031364</td>\n",
              "      <td>-0.032284</td>\n",
              "      <td>0.011249</td>\n",
              "      <td>-0.088017</td>\n",
              "      <td>-0.019111</td>\n",
              "      <td>-0.030357</td>\n",
              "      <td>-0.061385</td>\n",
              "      <td>0.025453</td>\n",
              "      <td>0.021155</td>\n",
              "      <td>0.028687</td>\n",
              "      <td>-0.005571</td>\n",
              "      <td>0.062329</td>\n",
              "      <td>0.098726</td>\n",
              "      <td>0.092384</td>\n",
              "      <td>0.046759</td>\n",
              "      <td>-0.005907</td>\n",
              "      <td>0.105957</td>\n",
              "      <td>0.109298</td>\n",
              "      <td>0.059175</td>\n",
              "      <td>0.122534</td>\n",
              "      <td>0.153029</td>\n",
              "      <td>...</td>\n",
              "      <td>0.192317</td>\n",
              "      <td>0.246550</td>\n",
              "      <td>0.233467</td>\n",
              "      <td>0.262693</td>\n",
              "      <td>0.287298</td>\n",
              "      <td>0.231683</td>\n",
              "      <td>0.298521</td>\n",
              "      <td>0.220517</td>\n",
              "      <td>0.258794</td>\n",
              "      <td>0.230829</td>\n",
              "      <td>0.232522</td>\n",
              "      <td>0.256495</td>\n",
              "      <td>0.241966</td>\n",
              "      <td>0.254071</td>\n",
              "      <td>0.217664</td>\n",
              "      <td>0.271645</td>\n",
              "      <td>0.258605</td>\n",
              "      <td>0.221307</td>\n",
              "      <td>0.232253</td>\n",
              "      <td>0.247092</td>\n",
              "      <td>0.291971</td>\n",
              "      <td>0.234135</td>\n",
              "      <td>0.195564</td>\n",
              "      <td>0.223281</td>\n",
              "      <td>0.295235</td>\n",
              "      <td>0.248115</td>\n",
              "      <td>0.288305</td>\n",
              "      <td>0.289201</td>\n",
              "      <td>0.199776</td>\n",
              "      <td>0.231564</td>\n",
              "      <td>0.220040</td>\n",
              "      <td>0.175154</td>\n",
              "      <td>0.100520</td>\n",
              "      <td>-0.084716</td>\n",
              "      <td>-0.123486</td>\n",
              "      <td>-0.225727</td>\n",
              "      <td>-0.255724</td>\n",
              "      <td>-0.229396</td>\n",
              "      <td>-0.244727</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 501 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2         3    ...       497       498       499  500\n",
              "0 -0.005149 -0.001660 -0.003860 -0.003754  ... -0.015602 -0.018967 -0.014244  2.0\n",
              "1 -0.117753 -0.191172 -0.095776 -0.069015  ... -0.816351 -0.821680 -0.735269  2.0\n",
              "2 -0.531884 -0.102584 -0.307340  0.154307  ... -1.605749 -2.118144 -1.814519  2.0\n",
              "3 -0.135808 -0.096242 -0.119334 -0.021121  ... -0.637880 -0.528150 -0.454956  2.0\n",
              "4 -0.030297 -0.074934 -0.028709 -0.047723  ... -0.255724 -0.229396 -0.244727  2.0\n",
              "\n",
              "[5 rows x 501 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EF2Nj27l2L77"
      },
      "source": [
        "## Questão 1 - Criar vetor de atributos dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "fgs8Qlqgh191",
        "outputId": "a38116a1-5cbe-474f-8e39-159ec86cf789"
      },
      "source": [
        "#calculando as estatísticas dos dados\n",
        "a1 = [dados.iloc[i, :].mean() for i in range(len(dados))]\n",
        "a2 = [dados.iloc[i, :].std() for i in range(len(dados))]\n",
        "a3 = [ss.skew(dados.iloc[i, :]) for i in range(len(dados))]\n",
        "a4 = [ss.kurtosis(dados.iloc[i, :]) for i in range(len(dados))]\n",
        "a5 = dados.apply(lambda x: ss.iqr(x), axis=1)\n",
        "\n",
        "atributos = pd.DataFrame([a1, a2, a3, a4, a5]).T\n",
        "atributos.columns = ['Média', 'Desvio padrão', 'Assimetria', 'Curtose', 'Intervalo inter-quartil']\n",
        "atributos.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Média</th>\n",
              "      <th>Desvio padrão</th>\n",
              "      <th>Assimetria</th>\n",
              "      <th>Curtose</th>\n",
              "      <th>Intervalo inter-quartil</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.006098</td>\n",
              "      <td>0.090221</td>\n",
              "      <td>21.605849</td>\n",
              "      <td>475.056090</td>\n",
              "      <td>0.020396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.091002</td>\n",
              "      <td>0.554305</td>\n",
              "      <td>-0.258629</td>\n",
              "      <td>-0.789312</td>\n",
              "      <td>0.860058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.158652</td>\n",
              "      <td>1.078906</td>\n",
              "      <td>-0.340964</td>\n",
              "      <td>-0.964726</td>\n",
              "      <td>1.675028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.047457</td>\n",
              "      <td>0.317557</td>\n",
              "      <td>0.113890</td>\n",
              "      <td>1.611331</td>\n",
              "      <td>0.475802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.030319</td>\n",
              "      <td>0.188875</td>\n",
              "      <td>1.993624</td>\n",
              "      <td>21.961859</td>\n",
              "      <td>0.256980</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Média  Desvio padrão  Assimetria     Curtose  Intervalo inter-quartil\n",
              "0  0.006098       0.090221   21.605849  475.056090                 0.020396\n",
              "1  0.091002       0.554305   -0.258629   -0.789312                 0.860058\n",
              "2  0.158652       1.078906   -0.340964   -0.964726                 1.675028\n",
              "3  0.047457       0.317557    0.113890    1.611331                 0.475802\n",
              "4  0.030319       0.188875    1.993624   21.961859                 0.256980"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYMkqLqD2kaf"
      },
      "source": [
        "## Questão 2 - Implementação dos algoritmos KNN (K Nearest Neighbors) e MDC (Minimum Distance to Centroid)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wjw2WlJKcr35"
      },
      "source": [
        "class KNN:\n",
        "  def __init__(self, k):\n",
        "    self.k = k\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    self.X_train = X\n",
        "    self.y_train = y\n",
        "\n",
        "  def euclidean_distance(self, vetor, amostra):\n",
        "    r = list()\n",
        "\n",
        "    #calcula a distância euclidiana entre a amostra e cada linha do vetor\n",
        "    for row in vetor:\n",
        "      r.append(np.sqrt(np.sum(np.square(row - amostra))))\n",
        "    return r\n",
        "  \n",
        "  def calculate_k_neighbors_index(self, X_test):\n",
        "    distancias = list()\n",
        "\n",
        "    #calcula a distância euclidiana para cada amostra\n",
        "    for row in X_test:\n",
        "      distancias.append(self.euclidean_distance(self.X_train, row))\n",
        "\n",
        "    #reserva os índices dos elementos ordenados pela distância, da menor para a maior\n",
        "    indices = np.argsort(distancias)\n",
        "\n",
        "    #retorna apenas os índices do k vizinhos mais próximos p/ cada amostra (menores distâncias)\n",
        "    return indices[:, 0:self.k]\n",
        "\n",
        "  def predict(self, X_test):\n",
        "    lista_classes = list()\n",
        "    respostas = list()\n",
        "\n",
        "    indices_k_vizinhos = self.calculate_k_neighbors_index(X_test)\n",
        "\n",
        "    #reserva os valores das classes do k vizinhos mais próximos de cada amostra\n",
        "    for row in indices_k_vizinhos:\n",
        "      classes_k_vizinhos = self.y_train[row]\n",
        "      lista_classes.append(classes_k_vizinhos)\n",
        "\n",
        "    #calcula quantas vezes cada classe aparece entre os k vizinhos, para cada amostra, ordenadas da mais frequente para a menos frequente \n",
        "    #o primeiro elemento da tupla, c[0][0], representa a classe mais frequente, ou seja, a resposta do KNN.\n",
        "    for item in lista_classes:\n",
        "      c = Counter(item).most_common()\n",
        "      respostas.append(c[0][0])\n",
        "\n",
        "    return respostas\n",
        "\n",
        "  def score(self, X_test, y_real):\n",
        "    y_predito = self.predict(X_test)\n",
        "\n",
        "    acertos = 0\n",
        "\n",
        "    #calcula a proporção de quantas vezes o algoritmo fez uma previsão correta\n",
        "    for i in range(len(y_real)):\n",
        "      if y_real[i] == y_predito[i]:\n",
        "        acertos += 1\n",
        "\n",
        "    taxa_acerto = acertos / len(y_real)\n",
        "\n",
        "    return taxa_acerto"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtCDdSnNnd8_"
      },
      "source": [
        "### Testando o KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NayOZiREncJP"
      },
      "source": [
        "X = np.array(dados.drop(500, axis=1))\n",
        "y = np.array(dados[500])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mA9Gt7gdCCp"
      },
      "source": [
        "#normalizando os atributos para uma mesma escala\n",
        "mm = MinMaxScaler()\n",
        "X_norm = mm.fit_transform(X)\n",
        "\n",
        "#separando os dados em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.2)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1JO5laqw1Od",
        "outputId": "f56069ac-6edc-4435-85de-98652c65a1d9"
      },
      "source": [
        "#treinando o algoritmo para k = 3\n",
        "k = KNN(3)\n",
        "k.fit(X_train, y_train)\n",
        "\n",
        "#calculando a acurácia\n",
        "k.score(X_test, y_test)"
      ],
      "execution_count": 509,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.95"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 509
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8VJd0ZgGMuZ"
      },
      "source": [
        "### Implementando o MDC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqAzgn2EeSwp"
      },
      "source": [
        "class MDC:\n",
        "  \"\"\"\n",
        "  No MDC, cada classe de treino tem um centroide. Baseado nisso, recebemos novas amostras,\n",
        "  calculamos seus centroides e classificamos de acordo com o centroide mais próximo entre\n",
        "  os das classes de treino.\n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    self.X_train = X\n",
        "    self.y_train = y\n",
        "\n",
        "  def separate_classes(self, X, y):\n",
        "    #separa as amostras por classes, para calcular o centroide de cada uma\n",
        "\n",
        "    #encontra os valores únicos das classes\n",
        "    m = list(set(y)) \n",
        "    #guarda os índices e os valores de y\n",
        "    enum = list(enumerate(y)) \n",
        "\n",
        "    #dicionário com uma chave para cada classe\n",
        "    dicionario_y = {int(i): [] for i in m} \n",
        "\n",
        "    for k, v in dicionario_y.items():\n",
        "      for index, value in enum:\n",
        "        #separa as classes das amostras por índices\n",
        "        if int(value) == k: \n",
        "          v.append(index)\n",
        "\n",
        "    #encontrando as linhas de X correspondentes às de y, por classe\n",
        "    dicionario_x = {k: X[v] for k, v in dicionario_y.items()}\n",
        "\n",
        "    return dicionario_x\n",
        "\n",
        "  def calculate_centroids(self, X, y):\n",
        "    #calcula os centroides de cada classe\n",
        "\n",
        "    d = self.separate_classes(X, y)\n",
        "    centroids = [[k, np.mean(v)] for k, v in d.items()]\n",
        "\n",
        "    return centroids\n",
        "\n",
        "  def predict(self, X_test):\n",
        "    r = list()\n",
        "\n",
        "    centroides_treino = self.calculate_centroids(self.X_train, self.y_train)\n",
        "\n",
        "    #calculamos os centroides das amostras manualmente porque não temos os valores das classes, já que queremos prevê-las\n",
        "    centroides_amostras = list(enumerate([np.mean(row) for row in X_test]))\n",
        "\n",
        "    d = {i: [] for i in range(len(X_test))}\n",
        "\n",
        "    for row in centroides_amostras:\n",
        "      for i in range(len(centroides_treino)):\n",
        "        #reservamos em uma lista: o indice da amostra atual, o índice do centroide da classe atual e o valor absoluto\n",
        "        #da diferença entre o centroide da amostra atual e o centroide da classe atual\n",
        "        a = [row[0], centroides_treino[i][0], abs(row[1] - centroides_treino[i][1])]\n",
        "        r.append(a)\n",
        "\n",
        "    r = np.array(r)\n",
        "\n",
        "    respostas = list()\n",
        "\n",
        "    for i in range(len(r) - 1):\n",
        "      #verifica se estamos comparando as amostras de mesmo índice\n",
        "      if r[i, 0] == r[i+1, 0]: \n",
        "        #verificamos, para cada amostra, o menor valor entre as diferenças de seu centroide e os centroides das classes de treino,\n",
        "        #que corresponde ao terceiro elemento de r\n",
        "        min_centroid = min(r[i], r[i+1], key = lambda x: x[2])\n",
        "        respostas.append(min_centroid[1])\n",
        "\n",
        "    return respostas\n",
        "    \n",
        "\n",
        "  def score(self, X_test, y_real):\n",
        "    y_predito = self.predict(X_test)\n",
        "\n",
        "    acertos = 0\n",
        "\n",
        "    #calcula a proporção de quantas vezes o algoritmo fez uma previsão correta\n",
        "    for i in range(len(y_real)):\n",
        "      if y_real[i] == y_predito[i]:\n",
        "        acertos += 1\n",
        "\n",
        "    taxa_acerto = acertos / len(y_real)\n",
        "\n",
        "    return taxa_acerto"
      ],
      "execution_count": 517,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXdTmGnUCA50"
      },
      "source": [
        "## Questão 3 - Calcular a acurácia média após 10 realizações do MDC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAx-vyl2B5og",
        "outputId": "ae26cc96-7b10-43c4-8f38-8c0b495448a0"
      },
      "source": [
        "#os dados já foram separados na proporção sugerida, para fazer os testes de implementação dos algoritmos\n",
        "\n",
        "for i in range(10):\n",
        "  acuracias_mdc = list()\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.2)\n",
        "\n",
        "  m = MDC()\n",
        "  m.fit(X_train, y_train)\n",
        "  acuracias_mdc.append(m.score(X_test, y_test))\n",
        "\n",
        "print(f'Média de acurácia do MDC: {np.mean(acuracias_mdc)}')"
      ],
      "execution_count": 520,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Média de acurácia do MDC: 0.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfw3DHHgDBfv"
      },
      "source": [
        "## Questão 4 - Implementação da k-fold cross-validation e teste do KNN com K variando de 2 até 10, para uma 5-fold cv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWxciJis5e99"
      },
      "source": [
        "def kfoldcv(X, y, k, objeto_knn):\n",
        "  \"\"\"\n",
        "  O cross-validation utilizando k-fold consiste em dividir os dados em\n",
        "  k partes iguais (ou aproximadamente iguais), para treinar com todos os dados\n",
        "  \n",
        "  Nesse método, escolhemos aleatoriamente uma parte do dataset para teste, e\n",
        "  deixamos o restante para treino.\n",
        "  \"\"\"\n",
        "\n",
        "  tamanho_fold = round(len(X)/k)\n",
        "\n",
        "  #armazenamos e embaralhamos os índices dos dados para satisfazer a aleatoriedade\n",
        "  indices = list(range(len(X)))\n",
        "  random.shuffle(indices)\n",
        "\n",
        "  #criando os índices dos intervalos de dados de acordo com o tamanho de cada fold\n",
        "  folds = [indices[x:x+tamanho_fold] for x in range(0, len(indices), tamanho_fold)]\n",
        "\n",
        "  acuracias = list()\n",
        "\n",
        "  for i in range(k):\n",
        "    indices_teste = folds[i]\n",
        "    X_teste = X[indices_teste]\n",
        "    y_teste = y[indices_teste]\n",
        "\n",
        "    indices_treino = []\n",
        "    for fold in folds:\n",
        "      if fold != indices_teste:\n",
        "        indices_treino.append(fold)\n",
        "\n",
        "    #transformando a lista de listas em uma lista só\n",
        "    indices_treino = [item for outer_list in indices_treino for item in outer_list]\n",
        "    X_treino = X[indices_treino]\n",
        "    y_treino = y[indices_treino]\n",
        "\n",
        "    objeto_knn.fit(X_treino, y_treino)\n",
        "    acuracias.append(objeto_knn.score(X_teste, y_teste))\n",
        "\n",
        "  return np.mean(acuracias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfqGVvine7H5",
        "outputId": "cbbbc8c4-3b35-4cf6-98fe-2ed5329a28da"
      },
      "source": [
        "for i in range(2, 11):\n",
        "  k = KNN(i)\n",
        "\n",
        "  print('Acurácia média para K = ' + str(i) + ': ' + str(kfoldcv(X_norm, y, 5, k)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurácia média para K = 2: 0.97\n",
            "Acurácia média para K = 3: 0.9400000000000001\n",
            "Acurácia média para K = 4: 0.9800000000000001\n",
            "Acurácia média para K = 5: 0.96\n",
            "Acurácia média para K = 6: 0.93\n",
            "Acurácia média para K = 7: 0.97\n",
            "Acurácia média para K = 8: 0.99\n",
            "Acurácia média para K = 9: 0.9200000000000002\n",
            "Acurácia média para K = 10: 0.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHLs0UNPDPse"
      },
      "source": [
        "Para esse teste, o melhor valor de K foi 8."
      ]
    }
  ]
}